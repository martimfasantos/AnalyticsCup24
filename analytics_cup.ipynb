{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Disclaimer: We use some advanced packages here without detailed explanation. You can use these, but we do not provide any support.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install them, you can uncomment the following lines:\n",
    "# (%pip will call pip from the currently active python environment)\n",
    "\n",
    "# Note: Some of these packages are still not compatible with Python 3.12 yet\n",
    "# %pip install sweetviz\n",
    "# %pip install ydata_profiling\n",
    "# %pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"font-weight: bold;\"> Analytics Cup 2024 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "import shap\n",
    "from ydata_profiling import ProfileReport\n",
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "# pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Phase 1: Business Understanding </font>\n",
    "\n",
    "Business Understanding is the first and economically most important step in the\n",
    "CRISP-DM process. It serves to assess use cases, feasibility, requirements, and\n",
    "risks of the endeavored data driven project. Since the conduction of data driven\n",
    "projects usually depends on the data at hand, the CRISP-DM process often \n",
    "alternates between Business Understanding and Data Understanding, until the\n",
    "project's schedule becomes sufficiently clear.\n",
    "\n",
    "#### Business Understanding\n",
    "\n",
    "In LLMeals Analytics Cup, the goal is to improve customer satisfaction and reduce subscription cancellations by developing a model that accurately predicts whether a customer likes (Like=1) or dislikes (Like=0) a suggested recipe. The model will utilize datasets such as \"recipes.csv,\" \"reviews.csv,\" \"diet.csv,\" and \"requests.csv\" to generate insights into user preferences. The successful model will serve as the foundation for enhancing the quality of suggested recipes in LLMeals' service, aligning them more closely with individual customer requirements. The project's ultimate aim is to leverage data-driven approaches for refining the recipe suggestions and, in turn, improving the overall LLMeals user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Phase 2: Data Understanding </font>\n",
    "\n",
    "The *Data Understanding* phase mainly serves to inform the Business Understanding step by\n",
    "assessing the data quality and content, and should provide the engineers with \n",
    "an intuition for the specific data and the specific problem at hand. Experienced\n",
    "data scientists and machine learning engineers can often estimate the difficulty\n",
    "and feasibility of the task by analyzing and understanding the data.  \n",
    "\n",
    "#### Example: Data Understanding\n",
    "\n",
    "Make yourself familiar with the structure and content of the data. *Note*, this step \n",
    "heavily depends on the specific problem at hand, since there is no fixed recipe that \n",
    "fits all possible data sets. In the example below, we are only looking at a very small\n",
    "data set and do **not** conduct an in-depth analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "file_dir = \"datasets/original\"\n",
    "file_names = [\"reviews.csv\", \"requests.csv\", \"diet.csv\", \"recipes.csv\"]\n",
    "reviews = pd.read_csv(f'{file_dir}/{file_names[0]}', low_memory=False)\n",
    "requests = pd.read_csv(f'{file_dir}/{file_names[1]}')\n",
    "diet = pd.read_csv(f'{file_dir}/{file_names[2]}')\n",
    "recipes = pd.read_csv(f'{file_dir}/{file_names[3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reviews.sample(3))\n",
    "# print(\"\\n\")\n",
    "# print(reviews.info())\n",
    "# print(\"\\n\")\n",
    "# print(reviews.describe())\n",
    "# sns.boxplot(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(requests.sample(3))\n",
    "# print(\"\\n\")\n",
    "# print(requests.info())\n",
    "# print(\"\\n\")\n",
    "# print(requests.describe())\n",
    "# sns.boxplot(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(diet.sample(3))\n",
    "# print(\"\\n\")\n",
    "# print(diet.info())\n",
    "# print(\"\\n\")\n",
    "# print(diet.describe())\n",
    "# sns.boxplot(diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(recipes.sample(3))\n",
    "# print(\"\\n\")\n",
    "# print(recipes.info())\n",
    "# print(\"\\n\")\n",
    "# print(recipes.describe())\n",
    "# plt.figure(figsize=(24, 6))\n",
    "# sns.boxplot(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the balancing of classes/labels\n",
    "# print(reviews.groupby(\"Like\").size())\n",
    "\n",
    "# # -> 2 classes, 1 is much more frequent than the other (False/True ratio is ~4:1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the feature distributions with a pairplot,\n",
    "# as it gives you a good overview over possible outliers\n",
    "# and a good overview over the data in general\n",
    "\n",
    "# pairplot for the full data\n",
    "# columns_to_drop = [\"AuthorId\", \"RecipeId\", \"TestSetId\"]\n",
    "# sns.pairplot(reviews.drop(columns_to_drop, axis=1), hue=\"Like\", diag_kind=\"hist\", diag_kws={\"multiple\" : \"stack\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requests Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the feature distributions with a pairplot,\n",
    "# as it gives you a good overview over possible outliers\n",
    "# and a good overview over the data in general\n",
    "\n",
    "# pairplot for the full data\n",
    "# columns_to_drop = [\"AuthorId\", \"RecipeId\"]\n",
    "# data = pd.merge(requests, reviews[[\"AuthorId\", \"RecipeId\", \"Like\"]], on=['AuthorId','RecipeId'], \\\n",
    "#     how='left').drop(columns_to_drop, axis=1)\n",
    "# sns.pairplot(data, hue=\"Like\", diag_kind=\"hist\", diag_kws={\"multiple\" : \"stack\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diet Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot for the full data\n",
    "# columns_to_drop = [\"AuthorId\"]\n",
    "# data = pd.merge(diet, reviews[[\"AuthorId\", \"Like\"]], on=['AuthorId'], how='left').drop(columns_to_drop, axis=1)\n",
    "# sns.pairplot(data, hue=\"Like\", diag_kind=\"hist\", diag_kws={\"multiple\" : \"stack\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipes Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot for the full data\n",
    "# columns_to_drop = [\"RecipeId\"]\n",
    "# data = pd.merge(recipes, reviews[[\"RecipeId\", \"Like\"]], on=['RecipeId'], how='left').drop(columns_to_drop, axis=1)\n",
    "# sns.pairplot(data, hue=\"Like\", diag_kind=\"hist\", diag_kws={\"multiple\" : \"stack\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a merged dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **File**     | **Join Keys**            |\n",
    "|--------------|------------------------|\n",
    "| reviews.csv  | AuthorId, RecipeId     |\n",
    "| requests.csv | AuthorId, RecipeId     |\n",
    "| diet.csv     | AuthorId               |\n",
    "| recipes.csv  | RecipeId               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge the dataframes using multiple columns\n",
    "# merged_df = pd.merge(reviews, requests, on=['AuthorId','RecipeId'], how='left')\n",
    "# merged_df = pd.merge(merged_df, diet, on='AuthorId', how='left')\n",
    "# merged_df = pd.merge(merged_df, recipes, on='RecipeId', how='left')\n",
    "\n",
    "# # Save the merged dataframe to a new CSV file\n",
    "# merged_df.to_csv('datasets/original/merged_data.csv', index=False)\n",
    "\n",
    "# # Check if the number of rows and columns are correct\n",
    "# print(len(merged_df) == len(reviews))\n",
    "# print(reviews.shape)\n",
    "# print(merged_df.shape)\n",
    "# print(merged_df.shape[1] == reviews.shape[1] + requests.shape[1]-2 + diet.shape[1]-1 + recipes.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "file_dir = \"datasets/original\"\n",
    "file_name = \"merged_data.csv\"\n",
    "df = pd.read_csv(f'{file_dir}/{file_name}', low_memory=False)\n",
    "index_column = df.columns[0]\n",
    "df.drop([index_column], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class-dependent pairplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at class-dependent pairplots\n",
    "# _df = df.drop([\"AuthorId\", \"RecipeId\", \"TestSetId\"], axis=1, inplace=False)\n",
    "# df_grouped_by_class = _df.groupby(by=\"Like\")\n",
    "\n",
    "# df_true = df_grouped_by_class.get_group(True)\n",
    "# df_false = df_grouped_by_class.get_group(False)\n",
    "\n",
    "# class_labels = {\n",
    "#     \"True\" : {\n",
    "#         \"color\" : \"blue\",\n",
    "#         \"data\" : df_true\n",
    "#     },\n",
    "#     \"False\" : {\n",
    "#         \"color\" : \"green\",\n",
    "#         \"data\" : df_false\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# for class_i in class_labels:\n",
    "#     class_color = class_labels[class_i][\"color\"]\n",
    "#     class_df = class_labels[class_i][\"data\"]\n",
    "#     p = sns.pairplot(class_df, diag_kind=\"hist\", diag_kws={\"color\" : class_color}, plot_kws={\"color\" : class_color, \"label\" : class_i})\n",
    "#     p.fig.suptitle(class_i, y=1.0, size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can also leverage the dataprep package to get a nice summary report\n",
    "# report = sv.analyze(df)\n",
    "# report.show_notebook()\n",
    "\n",
    "# # We can also leverage the yadata_profiling package to get a nice summary report\n",
    "# profile = ProfileReport(df, title=\"LLMeals - Summary Report\")\n",
    "# profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: Data Understanding\n",
    "\n",
    "You should have a good understanding what the data is about and of some of its properties. Newly gained insights are used to reiterate the\n",
    "Business Understanding Phase, but in this example, it won't be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Phase 3: Data Preparation </font>\n",
    "\n",
    "Data Preparation mainly consists of two parts, Data Cleaning and Data Wrangling. In Data\n",
    "Cleaning, the goal is assure data quality. This includes removing wrong/corrupt \n",
    "data entries and making sure the entries are standardized, e.g. enforcing certain encodings. \n",
    "Data Wrangling then transforms the data in order to make it suitable for the modelling step.\n",
    "Sometimes, steps from Data Wrangling are incorporated into the automatized Pipeline, as\n",
    "we will show in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical vars:  ['Diet', 'Name', 'RecipeCategory', 'RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeYield']\n",
      "Boolean vars:  ['Like', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar', 'HighFiber']\n",
      "Non-numeric vars:  ['Diet', 'Name', 'RecipeCategory', 'RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeYield', 'Like', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar', 'HighFiber']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "file_source_path = 'datasets/original/merged_data.csv' # source file\n",
    "file_dir = 'datasets/encoded' # destination directory\n",
    "file_tag = 'dataset'\n",
    "\n",
    "df = pd.read_csv(file_source_path, low_memory=False)\n",
    "index_column = df.columns[0]\n",
    "df.drop([index_column], axis=1, inplace=True)\n",
    "\n",
    "# Like: object -> bool\n",
    "# HighProtein: {Indiferent, Yes} - object -> bool\n",
    "# LowSugar: {0, Indiferent} - object -> bool\n",
    "# Diet: {Vegetarian, Omnivore, Vegan} - object -> categorical\n",
    "# Name: 140k values, 50% distinct - object -> categorical\n",
    "# RecipeCategory: 7 categories - object -> categorical\n",
    "# RecipeIngredientQuantities: filter\n",
    "# RecipeIngredientParts: filter\n",
    "# RecipeYield: 46k values, 7.9k distinct, 93.8k missing - object -> categorical\n",
    "\n",
    "\n",
    "# --------------------------------------------------------- #\n",
    "# IMPORTANT: call this function after loading the dataframe #\n",
    "# --------------------------------------------------------- #\n",
    "def convert_variable_types(df: DataFrame):\n",
    "    for c in df.columns:\n",
    "        uniques = df[c].dropna(inplace=False).unique()\n",
    "        if len(uniques) == 2:\n",
    "            df[c] = df[c].astype('bool')\n",
    "        elif df[c].dtype == 'int64' or df[c].dtype == 'float64':\n",
    "            continue # do nothing, already correct type\n",
    "        else:\n",
    "            df[c] = df[c].astype('category')\n",
    "\n",
    "# ----------- Convertions ----------- #\n",
    "# df[\"Like\"] = df[\"Like\"].astype('category')\n",
    "# df[\"HighProtein\"] = df[\"HighProtein\"].astype('category')\n",
    "# df[\"LowSugar\"] = df[\"LowSugar\"].astype('category')\n",
    "# df[\"Diet\"] = df[\"Diet\"].astype('category')\n",
    "# df[\"Name\"] = df[\"Name\"].astype('category')\n",
    "# df[\"RecipeCategory\"] = df[\"RecipeCategory\"].astype('category')\n",
    "# df[\"RecipeYield\"] = df[\"RecipeYield\"].astype('category')\n",
    "# df[\"RecipeIngredientQuantities\"] = df[\"RecipeIngredientQuantities\"].astype('category')\n",
    "# df[\"RecipeIngredientParts\"] = df[\"RecipeIngredientParts\"].astype('category')\n",
    "# df[\"AuthorId\"] = df[\"AuthorId\"].astype('category')\n",
    "# Note: \"Rating\" was kept as float64 to allow for decimal values\n",
    "\n",
    "# convert all variables to the correct type\n",
    "convert_variable_types(df)\n",
    "\n",
    "# save the categorical variables\n",
    "categorical_vars = [column for column in df.columns if df[column].dtype.name == 'category']\n",
    "print(\"Categorical vars: \", categorical_vars)\n",
    "\n",
    "# save the boolean variables\n",
    "bool_vars = [column for column in df.columns if df[column].dtype.name == 'bool']\n",
    "print(\"Boolean vars: \", bool_vars)\n",
    "\n",
    "# save the non-numeric variables\n",
    "non_numeric_vars = categorical_vars + bool_vars\n",
    "print(\"Non-numeric vars: \", non_numeric_vars)\n",
    "\n",
    "# convert categorical variables to numerical\n",
    "for c in categorical_vars:\n",
    "    le = LabelEncoder()\n",
    "    df[c] = le.fit_transform(df[c])\n",
    "\n",
    "df.to_csv(f'{file_dir}/{file_tag}_encoded.csv', index=True)\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "# # filter RecipeIngredientQuantities\n",
    "# import re\n",
    "# from fractions import Fraction\n",
    "\n",
    "# # Function to convert a string to a list of floats with fractions\n",
    "# def convert_to_float_array(value):\n",
    "#     clean_values = value.replace('c(', '').replace('\"', '').replace('\\\\', '').replace(')', '').split(',')\n",
    "#     result = []\n",
    "#     for item in clean_values:\n",
    "#         # Skip empty strings\n",
    "#         if item:\n",
    "#             # Check for mixed fractions with a space before them\n",
    "#             if ' ' in item:\n",
    "#                 whole_part, fraction_part = item.split(' ')\n",
    "#                 result.append(float(whole_part) + float(Fraction(fraction_part)))\n",
    "#             else:\n",
    "#                 result.append(float(Fraction(item)))\n",
    "#     return result\n",
    "\n",
    "# # df['RecipeIngredientQuantities'] = df['RecipeIngredientQuantities'].astype(str)\n",
    "# print(df['RecipeIngredientQuantities'].head())\n",
    "# # print(x for x in df.iloc[0]['RecipeIngredientQuantities'])\n",
    "\n",
    "# df['RecipeIngredientQuantities'] = df['RecipeIngredientQuantities'].apply(convert_to_float_array)\n",
    "\n",
    "# # Flatten the lists and remove None values\n",
    "# # df['RecipeIngredientQuantities'] = df['RecipeIngredientQuantities'].apply(lambda x: item for sublist in x \\\n",
    "# #                                                         if sublist is not None and sublist != [] for item in sublist)\n",
    "\n",
    "# df['RecipeIngredientQuantities'].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Rating : 63087 (45.0%)\n",
      "TestSetId : 97381 (69.46%)\n",
      "RecipeServings : 50021 (35.68%)\n"
     ]
    }
   ],
   "source": [
    "# fill/remove/change missing/corrupt values\n",
    "from pandas import concat, DataFrame\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import nan\n",
    "\n",
    "file_source_path = 'datasets/encoded/dataset_encoded.csv' # source file\n",
    "file_dir = 'datasets/missing_values' # destination directory\n",
    "file_tag = 'dataset'\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(file_source_path, low_memory=False)\n",
    "convert_variable_types(df)\n",
    "index_column = df.columns[0]\n",
    "df.drop([index_column], axis=1, inplace=True)\n",
    "\n",
    "# --------------- #\n",
    "# Missing Values  #\n",
    "# --------------- #\n",
    "\n",
    "print(\"Missing values:\")\n",
    "for var in df:\n",
    "    nr = df[var].isna().sum()\n",
    "    if nr > 0:\n",
    "        print(f\"{var} : {nr} ({round(nr/df[var].shape[0]*100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the number of records to discard entire COLUMNS\n",
    "threshold = df.shape[0] * 0.90\n",
    "\n",
    "# drop columns with more missing values than the defined threshold\n",
    "missings = [c for c in mv.keys() if mv[c]>threshold]\n",
    "df = df.drop(columns=missings, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUX: Get variable types\n",
    "def get_variable_types(df: DataFrame) -> dict:\n",
    "    variable_types: dict = {\n",
    "        'Numeric': [],\n",
    "        'Binary': [],\n",
    "        'Categorical': []\n",
    "    }\n",
    "\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == 'bool':\n",
    "            variable_types['Binary'].append(c)\n",
    "        elif df[c].dtype == 'int64' or df[c].dtype == 'float64':\n",
    "            variable_types['Numeric'].append(c)\n",
    "        elif df[c].dtype == 'category':\n",
    "            variable_types['Categorical'].append(c)\n",
    "        else:\n",
    "            print(f'Unknown variable type for {c}')\n",
    "\n",
    "    return variable_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------- #\n",
    "# APPROACH 1: Fill with CONSTANT Value after DROP Missing Values #\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "# AUX: Fill with CONSTANT value\n",
    "def fill_with_constant(data: DataFrame) -> DataFrame:\n",
    "    tmp_nr, tmp_cat, tmp_bool = None, None, None\n",
    "    variables = get_variable_types(data)\n",
    "    numeric_vars = variables['Numeric']\n",
    "    categorical_vars = variables['Categorical']\n",
    "    binary_vars = variables['Binary']\n",
    "\n",
    "    if len(numeric_vars) > 0:\n",
    "        imp = SimpleImputer(strategy='constant', fill_value=0, missing_values=nan, copy=True)\n",
    "        tmp_nr = DataFrame(imp.fit_transform(data[numeric_vars]), columns=numeric_vars)\n",
    "    if len(categorical_vars) > 0:\n",
    "        imp = SimpleImputer(strategy='constant', fill_value=-1, missing_values=nan, copy=True)\n",
    "        tmp_cat = DataFrame(imp.fit_transform(data[categorical_vars]), columns=categorical_vars)\n",
    "    if len(binary_vars) > 0:\n",
    "        imp = SimpleImputer(strategy='constant', fill_value=False, missing_values=nan, copy=True)\n",
    "        tmp_bool = DataFrame(imp.fit_transform(data[binary_vars].astype(int)), columns=binary_vars).astype(bool)\n",
    "\n",
    "    df = concat([tmp_nr, tmp_cat, tmp_bool], axis=1)\n",
    "    df.index = data.index\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------------- #\n",
    "\n",
    "# Fill the rest with constant\n",
    "df_const = fill_with_constant(df)\n",
    "df_const.to_csv(f'{file_dir}/{file_tag}_drop_columns_then_constant.csv', index=True)\n",
    "# df_const.head()\n",
    "\n",
    "# Best results: Score = 0.533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------- #\n",
    "# APPROACH 2: Fill with CONSTANT Value after DROP Missing Values #\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "# AUX: Fill with MOST FREQUENT value\n",
    "def fill_with_most_frequent(data: DataFrame) -> DataFrame:\n",
    "    tmp_nr, tmp_cat, tmp_bool = None, None, None\n",
    "    variables = get_variable_types(data)\n",
    "    numeric_vars = variables['Numeric']\n",
    "    categorical_vars = variables['Categorical']\n",
    "    binary_vars = variables['Binary']\n",
    "\n",
    "    tmp_nr, tmp_cat, tmp_bool = None, None, None\n",
    "    if len(numeric_vars) > 0:\n",
    "        imp = SimpleImputer(strategy='mean', missing_values=nan, copy=True)\n",
    "        tmp_nr = DataFrame(imp.fit_transform(data[numeric_vars]), columns=numeric_vars)\n",
    "    if len(categorical_vars) > 0:\n",
    "        imp = SimpleImputer(strategy='most_frequent', missing_values=nan, copy=True)\n",
    "        tmp_cat = DataFrame(imp.fit_transform(data[categorical_vars]), columns=categorical_vars)\n",
    "    if len(binary_vars) > 0:\n",
    "        imp = SimpleImputer(strategy='most_frequent', missing_values=nan, copy=True)\n",
    "        tmp_bool = DataFrame(imp.fit_transform(data[binary_vars].astype(int)), columns=binary_vars).astype(bool)\n",
    "\n",
    "    df = concat([tmp_nr, tmp_cat, tmp_bool], axis=1)\n",
    "    df.index = data.index\n",
    "\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# Fill the rest with most frequent value\n",
    "df_most_freq = fill_with_most_frequent(df)\n",
    "df_most_freq.to_csv(f'{file_dir}/{file_tag}_drop_columns_then_most_frequent.csv', index=True)\n",
    "# df_most_freq.head()\n",
    "\n",
    "# Best results: Score = 0.533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore more approaches to fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling\n",
    "\n",
    "In contrast to Data Cleaning, Data Wrangling _transforms_ the dataset, in order\n",
    "to prepare it for the training of the models. This includes scaling, dimensionality\n",
    "reduction, data augmentation, outlier removal, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p-value may not be accurate for N > 5000.\n",
      "Input data for shapiro has range zero. The results may not be accurate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (140195, 29)\n",
      "Normal distributed variables: ['Rating']\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Best option\n",
    "file_source_path = 'datasets/missing_values/dataset_drop_columns_then_most_frequent.csv' # source file\n",
    "file_dir = 'datasets/outliers' # destination directory\n",
    "file_tag = 'dataset'\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(file_source_path, low_memory=False)\n",
    "convert_variable_types(df)\n",
    "index_column = df.columns[0]\n",
    "df.drop([index_column], axis=1, inplace=True)\n",
    "\n",
    "# non_numeric_vars =  ['Diet', 'Name', 'RecipeCategory', 'RecipeIngredientQuantities', 'RecipeIngredientParts', \\\n",
    "#                      'RecipeYield', 'Like', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar', 'HighFiber']\n",
    "\n",
    "numeric_vars = get_variable_types(df)['Numeric']\n",
    "# remove original non-numeric variables \n",
    "for var in numeric_vars.copy():\n",
    "    if var in non_numeric_vars:\n",
    "        numeric_vars.remove(var)\n",
    "\n",
    "# check for variables that are normally distributed\n",
    "norm_dist_variables = []\n",
    "for var in numeric_vars:\n",
    "    stat, p_value = shapiro(df[var])\n",
    "    # Interpret the result\n",
    "    alpha = 0.05\n",
    "    if p_value > alpha:\n",
    "        # The variable looks normally distributed (fail to reject H0)\n",
    "        norm_dist_variables.append(var)\n",
    "\n",
    "print('Original dataset:', df.shape)\n",
    "print('Normal distributed variables:', norm_dist_variables)\n",
    "# \"Rating\" is the only normally distributed variable but it only has 1 unique value in the dataset -> ignore it\n",
    "summary5 = df.describe(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_outlier_thresholds(summary5: DataFrame, var: str, OPTION: str, OUTLIER_PARAM: int):\n",
    "    # default parameter\n",
    "    if OPTION == 'iqr':\n",
    "        iqr = OUTLIER_PARAM * (summary5[var]['75%'] - summary5[var]['25%'])\n",
    "        top_threshold = summary5[var]['75%'] + iqr\n",
    "        bottom_threshold = summary5[var]['25%'] - iqr\n",
    "    # for normal distribution\n",
    "    elif OPTION == 'stdev':\n",
    "        std = OUTLIER_PARAM * summary5[var]['std']\n",
    "        top_threshold = summary5[var]['mean'] + std\n",
    "        bottom_threshold = summary5[var]['mean'] - std\n",
    "    else:\n",
    "        raise ValueError('Unknown outlier parameter!')\n",
    "    return top_threshold, bottom_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecipeId outliers: 0/140195\n",
      "Rating outliers: 0/140195\n",
      "TestSetId outliers: 42814/140195\n",
      "Time outliers: 436/97381\n",
      "Age outliers: 0/96945\n",
      "CookTime outliers: 212/96945\n",
      "PrepTime outliers: 890/96733\n",
      "Calories outliers: 39/95843\n",
      "FatContent outliers: 8/95804\n",
      "SaturatedFatContent outliers: 8/95796\n",
      "CholesterolContent outliers: 10/95788\n",
      "SodiumContent outliers: 109/95778\n",
      "CarbohydrateContent outliers: 56/95669\n",
      "FiberContent outliers: 10/95613\n",
      "SugarContent outliers: 274/95603\n",
      "ProteinContent outliers: 1/95329\n",
      "RecipeServings outliers: 31/95328\n",
      "Dataset after dropping outliers: (95297, 29)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- #\n",
    "# APPROACH 1: Drop outliers #\n",
    "# ------------------------- #\n",
    "\n",
    "# Tuned parameter to get the better results\n",
    "IQR_PARAM = 30\n",
    "\n",
    "data = df.copy(deep=True)\n",
    "\n",
    "for var in numeric_vars:\n",
    "    top_threshold, bottom_threshold = determine_outlier_thresholds(summary5, var, 'iqr', IQR_PARAM)\n",
    "    outliers = data[(data[var] > top_threshold) | (data[var] < bottom_threshold)]\n",
    "    print(f'{var} outliers: {outliers.shape[0]}/{data[var].shape[0]}')\n",
    "    data.drop(outliers.index, axis=0, inplace=True)\n",
    "data.to_csv(f'datasets/outliers/{file_tag}_drop_outliers.csv', index=True)\n",
    "print('Dataset after dropping outliers:', data.shape)\n",
    "\n",
    "# Best results: Score = 0.803\n",
    "\n",
    "# IQR_PARAM results:\n",
    "#    IQR    |   20    |   25    |   30    |   35    |   40    |\n",
    "# --------- |---------|---------|---------|---------|---------|\n",
    "#   Score   |  0.803  |  0.803  |  0.803  |  0.803  |  0.803  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after truncating outliers: (140195, 29)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------- #\n",
    "# APPROACH 2: Truncate outliers #\n",
    "# ----------------------------- #\n",
    "\n",
    "# Tuned parameter to get the better results\n",
    "IQR_PARAM = 20\n",
    "\n",
    "data = df.copy(deep=True)\n",
    "\n",
    "for var in numeric_vars:\n",
    "    top_threshold, bottom_threshold = determine_outlier_thresholds(summary5, var, 'iqr', IQR_PARAM)\n",
    "    original_column = data[var].copy()\n",
    "    data[var] = data[var].apply(lambda x: top_threshold if x > top_threshold else bottom_threshold if x < bottom_threshold else x)\n",
    "    # print(f'{var} outliers: {(data[var] != original_column).sum()}/{data[var].shape[0]}')\n",
    "data.to_csv(f'datasets/outliers/{file_tag}_truncate_outliers_{IQR_PARAM}.csv', index=True)\n",
    "print('Dataset after truncating outliers:', data.shape)\n",
    "    \n",
    "# Best results: Score = 0.803\n",
    "\n",
    "# IQR_PARAM results:\n",
    "#    IQR    |   20    |   25    |   30    |   35    |   40    |\n",
    "# --------- |---------|---------|---------|---------|---------|\n",
    "#   Score   |  0.803  |  0.803  |  0.803  |  0.803  |  0.512  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1084077941.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1170], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    from sklearn.preprocessing import StandardScaler, MinMaxScaler, Z-score\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### data wrangling\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Z-score\n",
    "\n",
    "# data scaling\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# dimensionality reduction\n",
    "transform_pca = PCA()\n",
    "\n",
    "# value imputing\n",
    "\n",
    "# outlier detection/removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a cleaned data set, and before we start the *Modelling* phase, we are going to split our data set into multiple sub-datasets. \n",
    "Here, we are going to split it into an *train* and *test* data set. Note that the split strongly depends on the underlying use-case\n",
    "and used dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into learning and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_source_path = 'datasets/outliers/BEST_OUTLIERS.csv' # source file\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv(f'{file_source_path}', low_memory=False)\n",
    "# convert variable types\n",
    "convert_variable_types(df)\n",
    "# remove index column\n",
    "index_column = df.columns[0]\n",
    "df = df.drop([index_column], axis=1)\n",
    "# Drop TestSetId column and Like NaN rows (no way to know if they liked or not)\n",
    "df.drop('TestSetId', axis=1, inplace=True)\n",
    "df.dropna(subset=[target], inplace=True)\n",
    "\n",
    "y = df.pop(target).values\n",
    "X = df.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y,\n",
    "                test_size=0.3, \n",
    "                shuffle=True,\n",
    "                random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Phase 4: Modeling </font>\n",
    "\n",
    "In this phase, the model is trained and tuned. In general, data transformations\n",
    "from data wrangling can be part of a machine learning pipeline, and can therefore\n",
    "be tuned as well. (See CRISP-DM: DataPrep <--> Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n    U, S, Vt = self._fit(X)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py\", line 456, in _fit\n    X = self._validate_data(\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 577, in _validate_data\n    X = check_array(X, input_name=\"X\", **check_params)\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 899, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\marty\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[901], line 59\u001b[0m\n\u001b[0;32m     50\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline,\n\u001b[0;32m     51\u001b[0m                       meta_parameter_grid, \n\u001b[0;32m     52\u001b[0m                       scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m                       error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# here, the actual training and grid search happens\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest parameter:\u001b[39m\u001b[38;5;124m\"\u001b[39m, search\u001b[38;5;241m.\u001b[39mbest_params_ ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(CV score=\u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Here, you want to find the best classifier. As candidates, consider\n",
    "#   1. LogisticRegression\n",
    "#   2. RandomForestClassifier\n",
    "#   3. other algorithms from sklearn (easy to add)\n",
    "#   4. custom algorithms (more difficult to implement)\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_logistic_regression = LogisticRegression(max_iter=30)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "\n",
    "# train the models\n",
    "pipeline = Pipeline(steps=[(\"scaler\", transform_scaler), \n",
    "                           (\"pca\", transform_pca),\n",
    "                           (\"model\", None)])\n",
    "\n",
    "parameter_grid_preprocessing = {\n",
    "  # \"pca__n_components\" : [1, 2, 3, 4],\n",
    "  \"pca__n_components\" : [df.shape[1]-12, df.shape[1]-8, df.shape[1]-5, df.shape[1]]\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "  \"model\" : [model_logistic_regression],\n",
    "  \"model__C\" : [0.1, 1, 10],  # inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "  \"model\" : [model_gradient_boosting],\n",
    "  \"model__n_estimators\" : [10, 20, 30]\n",
    "}\n",
    "\n",
    "parameter_grid_random_forest = {\n",
    "  \"model\" : [model_random_forest],\n",
    "  \"model__n_estimators\" : [10, 20, 50],  # number of max trees in the forest\n",
    "  \"model__max_depth\" : [2, 3, 4],\n",
    "}\n",
    "\n",
    "meta_parameter_grid = [parameter_grid_logistic_regression,\n",
    "                       parameter_grid_random_forest,\n",
    "                       parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid, \n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2, \n",
    "                      cv=5,  # number of folds for cross-validation \n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# here, the actual training and grid search happens\n",
    "search.fit(X_train, y_train.ravel())\n",
    "\n",
    "print(\"best parameter:\", search.best_params_ ,\"(CV score=%0.3f)\" % search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Step 5: Evaluation </font>\n",
    "\n",
    "Once the appropriate models are chosen, they are evaluated on the test set. For\n",
    "this, different evaluation metrics can be used. Furthermore, this step is where\n",
    "the models and their predictions are analyzed resp. different properties, including\n",
    "feature importance, robustness to outliers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_test, y_test.ravel()))\n",
    "\n",
    "# contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_test), y_test.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional, if you're curious) \n",
    "# for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretability\n",
    "\n",
    "##### Disclaimer: This only works if shap is installed.\n",
    "\n",
    "In addition to models and their predictions, it is often important to understand _why_ a model makes certain predictions. \n",
    "There is a lot of literature on how this can be achieved (explainability), but we will only show the use of Shapley values\n",
    "using the python module \"shap\", which is a combination of Shapley values and LIME. \n",
    "You can find more information on this topic [here](https://christophm.github.io/interpretable-ml-book/shap.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume random forest model\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# compute shapley values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "\n",
    "expected_value = explainer.expected_value\n",
    "print(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dependent plots of shapley values for each feature\n",
    "for i,c in enumerate(df.variety.unique()):\n",
    "    shap.summary_plot(shap_values[i], X_train, show=False)\n",
    "    plt.title(\"Shapley values for \"+str(c))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the computed SHAP values, we can interpret that the *petal.width* has a positive impact on the output of the model \n",
    "if the feature value is moderate. For high aand low values, the impact is negative. The same observation\n",
    "holds for *petal.length*. Besides, the impact of the *sepal.length* and *sepal.width* features are rather low. By impact on a \n",
    "the target, we model the probability that we classify that target. Thus, if *petal.width* is high, it is more likely\n",
    "that we classify the data point as Versicolor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Step 6: Deployment </font>\n",
    "\n",
    "Now that you have chosen and trained your model, it is time to deploy it to your\n",
    "clients system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_service_classify_iris(datapoint):\n",
    "    \n",
    "  # make sure the provided datapoints adhere to the correct format for model input\n",
    "\n",
    "  # fetch your trained model\n",
    "  model = search.best_estimator_\n",
    "\n",
    "  # make prediction with the model\n",
    "  prediction = model.predict(datapoint)\n",
    "\n",
    "  return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetical new batch of flowers arrives\n",
    "from scipy.stats import norm\n",
    "\n",
    "amount_of_new_flowers = 9\n",
    "df_flowers = pd.DataFrame(columns=df.columns.drop(\"variety\"), index=range(1, amount_of_new_flowers+1))\n",
    "\n",
    "for i in df_flowers.index:\n",
    "  df_flowers.loc[i, \"sepal.length\"] = norm(loc=6, scale=2).rvs()\n",
    "  df_flowers.loc[i, \"sepal.width\"] = norm(loc=3, scale=1).rvs()\n",
    "  df_flowers.loc[i, \"petal.length\"] = norm(loc=3, scale=5).rvs()\n",
    "  df_flowers.loc[i, \"petal.width\"] = norm(loc=2, scale=2).rvs()\n",
    "\n",
    "# customer uses your micro service to determine the varieties\n",
    "df_flowers[\"variety\"] = micro_service_classify_iris(df_flowers)\n",
    "print(df_flowers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Analytics Cup, you need to export your prediction in a very specific output format. This is a csv file without an index and two columns, *id* and *prediction*. Note that the values in both columns need to be integer values, and especially in the *prediction* column either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "output = pd.DataFrame(df_flowers.variety)\n",
    "output['id'] = df_flowers.index\n",
    "output = output.rename(columns={'variety': 'prediction'})\n",
    "output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "output.to_csv('iris_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
